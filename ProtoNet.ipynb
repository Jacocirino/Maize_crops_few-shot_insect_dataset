{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"ProtoNet.ipynb","provenance":[],"collapsed_sections":["N-k-O6jYnLxn","k6jE0orVnvAM"],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","source":["<a href=\"https://github.com/\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n","\n","<!-- href=\"https://colab.research.google.com/github/cnielly/prototypical-networks-omniglot/blob/master/prototypical_networks_pytorch_omniglot.ipynb\" -->"],"metadata":{"id":"gEyxyTwFZQjv"}},{"cell_type":"markdown","metadata":{"id":"uHcKO4bWXi1Q"},"source":["# Few-shot learning via multi-layer feature fusion and relative entropy for maize crops insect classification"]},{"cell_type":"markdown","metadata":{"id":"96ByjQStXw9K"},"source":["## Import Packages"]},{"cell_type":"code","metadata":{"id":"DSqaLLXOXhNg","executionInfo":{"status":"ok","timestamp":1642808330923,"user_tz":180,"elapsed":312,"user":{"displayName":"Cirino Jacó","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03506022501076698368"}}},"source":["import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import cv2\n","from scipy import ndimage\n","import multiprocessing as mp\n","\n","import torch\n","import torch.nn as nn\n","import torchvision\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.autograd import Variable\n","\n","#Check GPU support, please do activate GPU\n","print(torch.cuda.is_available())"],"execution_count":21,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JRxOK8ydYEYY"},"source":["## Import the dataset"]},{"cell_type":"code","metadata":{"id":"QwYfJFkPX87_","executionInfo":{"status":"ok","timestamp":1642808335841,"user_tz":180,"elapsed":304,"user":{"displayName":"Cirino Jacó","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03506022501076698368"}}},"source":["!gdown --id 1DkabY6V-2WGkgAiXRmH4DtEE5Y4ZrHiH"],"execution_count":22,"outputs":[]},{"cell_type":"code","source":["!unzip insect_maize_dataset.zip"],"metadata":{"id":"ca4RzH50Qwoh","executionInfo":{"status":"ok","timestamp":1642808340168,"user_tz":180,"elapsed":285,"user":{"displayName":"Cirino Jacó","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03506022501076698368"}}},"execution_count":23,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qbmReKJ6YYz_"},"source":["## Read the dataset"]},{"cell_type":"code","metadata":{"id":"0UKXL8rwYPjN","executionInfo":{"status":"ok","timestamp":1642807920456,"user_tz":180,"elapsed":9,"user":{"displayName":"Cirino Jacó","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03506022501076698368"}}},"source":["def read_classes(class_path, class_name,nH): \n","    datax = []\n","    datay = []\n","    images = os.listdir(class_path)\n","    for img in images:\n","        image = cv2.resize(cv2.imread(class_path + '/' + img),(nH,nH))\n","\n","        # Rotate images to create new classes\n","        rotated_90 = ndimage.rotate(image, 90)\n","        rotated_180 = ndimage.rotate(image, 180)\n","        rotated_270 = ndimage.rotate(image, 270)\n","        datax.extend((image, rotated_90, rotated_180, rotated_270))\n","        datay.extend((\n","            class_name + '_0',\n","            class_name + '_90',\n","            class_name + '_180',\n","            class_name + '_270'\n","        ))\n","        \n","    return np.array(datax), np.array(datay)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"EC824lvtYgZB","executionInfo":{"status":"ok","timestamp":1642807920457,"user_tz":180,"elapsed":9,"user":{"displayName":"Cirino Jacó","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03506022501076698368"}}},"source":["def read_images(base_directory, nH):\n","    \"\"\"\n","    Reads all classes from the base_directory\n","    Uses multithreading to decrease the reading time\n","    \"\"\"\n","    datax = None\n","    datay = None\n","    \n","    pool = mp.Pool(mp.cpu_count())\n","    results = [pool.apply(read_classes, args=(base_directory + '/' + directory + '/', directory, nH,\n","                          )) for directory in os.listdir(base_directory)]\n","    pool.close()\n","\n","    for result in results:\n","        if datax is None:\n","            datax = result[0]\n","            datay = result[1]\n","        else:\n","            datax = np.vstack([datax, result[0]])\n","            datay = np.concatenate([datay, result[1]])\n","    return datax, datay"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["**Define image size**"],"metadata":{"id":"4I-Pqv4PQ7gy"}},{"cell_type":"code","source":["nH = 96 # image.shape = [nH,nH,3]"],"metadata":{"id":"VxpwKDhVQ8ZG","executionInfo":{"status":"ok","timestamp":1642807920457,"user_tz":180,"elapsed":8,"user":{"displayName":"Cirino Jacó","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03506022501076698368"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["**Read data**"],"metadata":{"id":"TZP1iN4NRAqv"}},{"cell_type":"code","source":["path_train = '/content/images/source'\n","path_test = '/content/images/target'"],"metadata":{"id":"s1ROCrwlRspD","executionInfo":{"status":"ok","timestamp":1642807920458,"user_tz":180,"elapsed":9,"user":{"displayName":"Cirino Jacó","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03506022501076698368"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"AsAcV7DGYjJo","executionInfo":{"status":"ok","timestamp":1642808355134,"user_tz":180,"elapsed":444,"user":{"displayName":"Cirino Jacó","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03506022501076698368"}}},"source":["%%time \n","trainx, trainy = read_images(path_train,nH)"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"LcuqY4nTYpJ2","executionInfo":{"status":"ok","timestamp":1642808359971,"user_tz":180,"elapsed":346,"user":{"displayName":"Cirino Jacó","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03506022501076698368"}}},"source":["%%time \n","testx, testy = read_images(path_test, nH)"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"uOB1VPAGYrss","executionInfo":{"status":"ok","timestamp":1642808364616,"user_tz":180,"elapsed":312,"user":{"displayName":"Cirino Jacó","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03506022501076698368"}}},"source":["trainx.shape, trainy.shape, testx.shape, testy.shape"],"execution_count":27,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AgHbmrAoY2yx"},"source":["## Create samples"]},{"cell_type":"code","metadata":{"id":"uO9FRXt8Yxre","executionInfo":{"status":"ok","timestamp":1642807928191,"user_tz":180,"elapsed":35,"user":{"displayName":"Cirino Jacó","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03506022501076698368"}}},"source":["def extract_sample(n_way, n_support, n_query, datax, datay):\n","  \"\"\"\n","  Picks random sample of size n_support+n_querry, for n_way classes\n","  Args:\n","      n_way (int): number of classes in a classification task\n","      n_support (int): number of labeled examples per class in the support set\n","      n_query (int): number of labeled examples per class in the query set\n","      datax (np.array): dataset of images\n","      datay (np.array): dataset of labels\n","  Returns:\n","      (dict) of:\n","        (torch.Tensor): sample of images. Size (n_way, n_support+n_query, (dim))\n","        (int): n_way\n","        (int): n_support\n","        (int): n_query\n","  \"\"\"\n","  sample = []\n","  K = np.random.choice(np.unique(datay), n_way, replace=False)\n","  for cls in K:\n","    datax_cls = datax[datay == cls]\n","    perm = np.random.permutation(datax_cls)\n","    sample_cls = perm[:(n_support+n_query)]\n","    sample.append(sample_cls)\n","  sample = np.array(sample)\n","  sample = torch.from_numpy(sample).float()\n","  sample = sample.permute(0,1,4,2,3)\n","  return({\n","      'images': sample,\n","      'n_way': n_way,\n","      'n_support': n_support,\n","      'n_query': n_query\n","      })"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"bAIY765lY8A3","executionInfo":{"status":"ok","timestamp":1642808911326,"user_tz":180,"elapsed":325,"user":{"displayName":"Cirino Jacó","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03506022501076698368"}}},"source":["def display_sample(sample):\n","  \"\"\"\n","  Displays sample in a grid\n","  Args:\n","      sample (torch.Tensor): sample of images to display\n","  \"\"\"\n","  # Need 4D tensor to create grid, currently 5D\n","  sample_4D = sample.view(sample.shape[0]*sample.shape[1],*sample.shape[2:])\n","  # Make a grid\n","  out = torchvision.utils.make_grid(sample_4D, nrow=sample.shape[1])\n","  plt.figure(figsize = (16,7))\n","  plt.imshow(out.permute(1, 2, 0))"],"execution_count":53,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sZuE6vuAZDIk"},"source":["Display a sample\n","\n","*   n_way = 5\n","*   n_support = 4\n","*   n_query = 3"]},{"cell_type":"code","metadata":{"id":"2a-YFFp3ZDup","executionInfo":{"status":"ok","timestamp":1642809208887,"user_tz":180,"elapsed":291,"user":{"displayName":"Cirino Jacó","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03506022501076698368"}}},"source":["sample_example = extract_sample(5, 4, 3, trainx, trainy)\n","# display_sample(sample_example['images'])\n","display_sample(F.normalize(sample_example['images'], p=10, dim=0))\n","sample_example['images'].shape # [N, k+q, chanels, width, height]"],"execution_count":57,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Rc71YDjybyI-"},"source":["## Build model"]},{"cell_type":"markdown","metadata":{"id":"N-k-O6jYnLxn"},"source":["### Model"]},{"cell_type":"code","metadata":{"id":"g8b5mUwFb0IT","executionInfo":{"status":"ok","timestamp":1642807929442,"user_tz":180,"elapsed":14,"user":{"displayName":"Cirino Jacó","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03506022501076698368"}}},"source":["class Flatten(nn.Module):\n","  def __init__(self):\n","    super(Flatten, self).__init__()\n","\n","  def forward(self, x):\n","    return x.view(x.size(0), -1)\n","\n","def load_protonet_conv(**kwargs):\n","  \"\"\"\n","  Loads the model\n","  Arg:\n","      x_dim (tuple): dimension of input image\n","      hid_dim (int): dimension of hidden layers in conv blocks\n","      z_dim (int): dimension of embedded image\n","  Returns:\n","      Model (Class ProtoNet)\n","  \"\"\"\n","  x_dim = kwargs['x_dim']\n","  hid_dim = kwargs['hid_dim']\n","  z_dim = kwargs['z_dim']\n","\n","  def conv_block(in_channels, out_channels):\n","    return nn.Sequential(\n","        nn.Conv2d(in_channels, out_channels, 3, padding=1),\n","        nn.BatchNorm2d(out_channels),\n","        nn.ReLU(),\n","        nn.Dropout(0.1),\n","        nn.MaxPool2d(3)\n","        )\n","    \n","  encoder = nn.Sequential(\n","        conv_block(x_dim[0], hid_dim[0]),\n","        conv_block(hid_dim[0], hid_dim[1]),\n","        conv_block(hid_dim[1], hid_dim[2]),\n","        conv_block(hid_dim[2], z_dim),\n","        Flatten()\n","  )\n","    \n","  return ProtoNet(encoder)"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"G5i1uAN-nPiQ"},"source":["### Encoder"]},{"cell_type":"code","metadata":{"id":"moqu8XJmcK2f","executionInfo":{"status":"ok","timestamp":1642807929443,"user_tz":180,"elapsed":14,"user":{"displayName":"Cirino Jacó","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03506022501076698368"}}},"source":["class ProtoNet(nn.Module):\n","  def __init__(self, encoder):\n","    \"\"\"\n","    Args:\n","        encoder : CNN encoding the images in sample\n","        n_way (int): number of classes in a classification task\n","        n_support (int): number of labeled examples per class in the support set\n","        n_query (int): number of labeled examples per class in the query set\n","    \"\"\"\n","    super(ProtoNet, self).__init__()\n","    # self.encoder1 = nn.Sequential(*list(encoder.children())[:1],\n","    #                     nn.MaxPool2d(5),\n","    #                     nn.MaxPool2d(5),\n","    #                     Flatten()\n","    #                     ).cuda()\n","    # self.encoder2 = nn.Sequential(*list(encoder.children())[:2],\n","    #                     nn.MaxPool2d(3),\n","    #                     nn.MaxPool2d(3),\n","    #                     Flatten()\n","    #                     ).cuda()\n","    # self.encoder3 = nn.Sequential(*list(encoder.children())[:3],\n","    #                     nn.MaxPool2d(3),\n","    #                     Flatten()\n","    #                     ).cuda()\n","    self.encoder = encoder.cuda()\n","\n","  def set_forward_loss(self, sample):\n","    \"\"\"\n","    Computes loss, accuracy and output for classification task\n","    Args:\n","        sample (torch.Tensor): shape (n_way, n_support+n_query, (dim))\n","    Returns:\n","        torch.Tensor: shape(2), loss, accuracy and y_hat\n","    \"\"\"\n","    sample_images = sample['images'].cuda()\n","    n_way = sample['n_way']\n","    n_support = sample['n_support']\n","    n_query = sample['n_query']\n","\n","    x_support = sample_images[:, :n_support]\n","    x_query = sample_images[:, n_support:]\n","   \n","    # Target indices are 0 ... n_way-1\n","    target_inds = torch.arange(0, n_way).view(n_way, 1, 1).expand(n_way, n_query, 1).long()\n","    target_inds = Variable(target_inds, requires_grad=False)\n","    target_inds = target_inds.cuda()\n","   \n","    # Encode images of the support and the query set\n","    x = torch.cat([x_support.contiguous().view(n_way * n_support, *x_support.size()[2:]),\n","                   x_query.contiguous().view(n_way * n_query, *x_query.size()[2:])], 0)\n","\n","    ##\n","    # f1 = self.encoder1.forward(x)\n","    # f2 = self.encoder2.forward(x)\n","    # f3 = self.encoder3.forward(x)\n","    f4 = self.encoder.forward(x)\n","\n","    z = f4\n","    # z = (f1 + f4) / 2\n","    # z = (f3 + f4) / 2\n","    # z = (f1 + f2 + f4) / 3\n","    # z = (f2 + f3 + f4) / 3\n","    # z = (f1 + f2 + f3 + f4) / 4\n","    ##\n","\n","    z_dim = z.size(-1)\n","\n","    # Z_PROTO\n","    z_proto = z[:n_way*n_support]\n","\n","    # Z_QUERY\n","    z_query = z[n_way*n_support:]\n","\n","    # Compute Squared Euclidean distance\n","    dists = euclidean_dist(z_query, z_proto.view(n_way, n_support, z_dim).mean(1))\n","\n","    # Compute probabilities, loss, y_hat, and accuracy\n","    log_p_y = F.log_softmax(-dists, dim=1).view(n_way, n_query, -1)\n","    loss_val = -log_p_y.gather(2, target_inds).squeeze().view(-1).mean()\n","    _, y_hat = log_p_y.max(2)\n","    acc_val = torch.eq(y_hat, target_inds.squeeze()).float().mean()\n","   \n","    return loss_val, {\n","        'loss': loss_val.item(),\n","        'acc': acc_val.item(),\n","        'y_hat': y_hat\n","        }"],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"k6jE0orVnvAM"},"source":["## Compute Squared Euclidean distance"]},{"cell_type":"code","metadata":{"id":"mRBdRY57cXJI","executionInfo":{"status":"ok","timestamp":1642807929445,"user_tz":180,"elapsed":15,"user":{"displayName":"Cirino Jacó","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03506022501076698368"}}},"source":["def euclidean_dist(x, y):\n","  \"\"\"\n","  Computes euclidean distance between x and y\n","  Args:\n","      x (torch.Tensor): shape (n, d). n usually n_way*n_query\n","      y (torch.Tensor): shape (m, d). m usually n_way\n","  Returns:\n","      torch.Tensor: shape(n, m). For each query, the euclidean distance to each centroid\n","  \"\"\"\n","  n = x.size(0)\n","  m = y.size(0)\n","  d = x.size(1)\n","  assert d == y.size(1)\n","\n","  x = x.unsqueeze(1).expand(n, m, d)\n","  y = y.unsqueeze(0).expand(n, m, d)\n","\n","  return torch.pow(x - y, 2).sum(2)"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"33fCxBpBcZRT"},"source":["## Training function"]},{"cell_type":"code","metadata":{"id":"qJntzyXDcfch","executionInfo":{"status":"ok","timestamp":1642807929846,"user_tz":180,"elapsed":416,"user":{"displayName":"Cirino Jacó","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03506022501076698368"}}},"source":["from tqdm import tqdm_notebook\n","from tqdm import tnrange\n","\n","def train(model, optimizer, train_x, train_y, n_way, n_support, n_query, max_epoch, epoch_size):\n","  \"\"\"\n","  Trains the protonet\n","  Args:\n","      model\n","      optimizer\n","      train_x (np.array): images of training set\n","      train_y(np.array): labels of training set\n","      n_way (int): number of classes in a classification task\n","      n_support (int): number of labeled examples per class in the support set\n","      n_query (int): number of labeled examples per class in the query set\n","      max_epoch (int): max epochs to train on\n","      epoch_size (int): episodes per epoch\n","  \"\"\"\n","  # divide the learning rate by 2 at each epoch, as suggested in paper\n","  scheduler = optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.5, last_epoch=-1)\n","  epoch = 0 #epochs done so far\n","  stop = False #status to know when to stop\n","\n","  while epoch < max_epoch and not stop:\n","    running_loss = 0.0\n","    running_acc = 0.0\n","\n","    for episode in tnrange(epoch_size, desc=\"Epoch {:d} train\".format(epoch+1)):\n","      sample = extract_sample(n_way, n_support, n_query, train_x, train_y)\n","      optimizer.zero_grad()\n","      loss, output = model.set_forward_loss(sample)\n","      \n","      running_loss += output['loss']\n","      running_acc += output['acc']\n","      loss.backward()\n","      optimizer.step()\n","    epoch_loss = running_loss / epoch_size\n","    epoch_acc = running_acc / epoch_size\n","    print('Epoch {:d} -- Loss: {:.4f} Acc: {:.4f}'.format(epoch+1,epoch_loss, epoch_acc))\n","\n","    epoch += 1\n","    scheduler.step()"],"execution_count":17,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A3AgopP_fhAL"},"source":["## Train and Test"]},{"cell_type":"code","metadata":{"id":"HTlfuM8gfyIL","executionInfo":{"status":"ok","timestamp":1642807929848,"user_tz":180,"elapsed":7,"user":{"displayName":"Cirino Jacó","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03506022501076698368"}}},"source":["def test(model, test_x, test_y, n_way, n_support, n_query, test_episode):\n","  running_loss = 0.0\n","  running_acc = 0.0\n","  for episode in tnrange(test_episode):\n","    sample = extract_sample(n_way, n_support, n_query, test_x, test_y)\n","    loss, output = model.set_forward_loss(sample)\n","    running_loss += output['loss']\n","    running_acc += output['acc']\n","  avg_loss = running_loss / test_episode\n","  avg_acc = running_acc / test_episode\n","  print('Test results -- Loss: {:.4f} Acc: {:.4f}'.format(avg_loss, avg_acc))"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"27KU-eJnXxtc","executionInfo":{"status":"ok","timestamp":1642808315539,"user_tz":180,"elapsed":283,"user":{"displayName":"Cirino Jacó","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03506022501076698368"}}},"source":["%%time\n","train_x = trainx\n","train_y = trainy\n","test_x = testx\n","test_y = testy\n","\n","max_epoch = 10\n","epoch_size = 2000\n","test_episode = 10000\n","\n","model = load_protonet_conv(\n","    x_dim=(3,nH,nH),\n","    hid_dim=(64,64,64),\n","    z_dim=64\n","    )\n","      \n","optimizer = optim.Adam(model.parameters(), lr = 0.001)\n","\n","n_way = 3\n","N_test = 3\n","n_support = 5\n","n_query = 5\n","\n","print('\\nTRAINING...')\n","train(model, optimizer, train_x, train_y, n_way, n_support, n_query, max_epoch, epoch_size)\n","\n","print('\\nTESTING...')\n","test(model, test_x, test_y, N_test, n_support, n_query, test_episode)"],"execution_count":20,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"MxgweFov2FYo","executionInfo":{"status":"ok","timestamp":1642808291782,"user_tz":180,"elapsed":34,"user":{"displayName":"Cirino Jacó","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03506022501076698368"}}},"execution_count":19,"outputs":[]}]}